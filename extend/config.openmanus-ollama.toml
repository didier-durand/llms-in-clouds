# smollm:360m via ollama
#$ ollama show smollm:360m
#  Model
#    architecture        llama
#    parameters          361.82M
#    context length      2048
#    embedding length    960
#    quantization        Q4_0
#
#  Parameters
#    stop           "<|im_start|>"
#    stop           "<|im_end|>"
#    temperature    0.2
#    top_p          0.9
#
#  License
#    Apache License
#    Version 2.0, January 2004

[llm]
model =  "smollm2:1.7b"
base_url = "http://127.0.0.1:11434/v1"
api_key = "<not-needed>"
max_tokens = 2048
temperature = 0.0